#!/usr/bin/env python

#    Copyright (C) 2012 10gen Inc.
#
#    This program is free software: you can redistribute it and/or  modify
#    it under the terms of the GNU Affero General Public License, version 3,
#    as published by the Free Software Foundation.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.

# Generates graphs from the results of the benchmark by taking a json
# file, results.json, as an argument.
# Usage: benchplot.py [results.json]
# results.json can be generated by running mongoexport on the results database.
# If no argument is given, the json will be read from standard input.

import json
import matplotlib.pyplot as plt
import numpy as np
import sys
from optparse import OptionParser

def total_ops(trial):
    """Calculate the total number of operations performed in this trial"""
    return sum(trial[op] for op in ['query', 'insert', 'update', 'delete'])

def summarize_data(data):
    """Calculate and return the number of threads, the average number of
    operations performed, and the average latency."""
    name = data['name']
    numThreads = data['numThreads']
    numTrials = data['numTrials']
    avgops = sum([total_ops(trial) for trial in data['trials']]) / numTrials
    avglat = sum([trial[name + 'LatencyAverageMs'] 
                    for trial in data['trials']]) / numTrials
                    
    return numThreads, avgops, avglat

def main():
    parser = OptionParser(usage="%prog [options] [results-file.json]")
    parser.add_option('-t', '--title', dest='title', default="Results",
                      help="The title to use when labeling the graph.")
    
    options, args = parser.parse_args()

    if len(args) > 0:
        f = open(args[0])
    else:
        f = sys.stdin

    allThreads = []
    allOps = []
    allLatency = []

    # go through and append the thread #, ops, and latency 
    # to the proper lists
    for line in f:
        data = json.loads(line.strip())
        threads, ops, lat = summarize_data(data)
        allThreads.append(threads)
        allOps.append(ops)
        allLatency.append(lat)

    coefficients = np.polyfit(allOps, allLatency, 1)
    equation = np.poly1d(coefficients)
    bestfit = equation(allOps)
    
    # Begin plotting code
    fig = plt.figure(1)

    ax = fig.add_subplot(111)
    for side in ['top', 'bottom', 'left', 'right']:
        ax.spines[side].set_color('none')
    ax.tick_params(labelcolor='none', top='off', bottom='off', 
                   left='off', right='off')
    ax.set_title(options.title)
    
    # plot threads vs operations
    ax = fig.add_subplot(311)
    ax.set_title('Threads vs. Ops/Sec')
    ax.set_xlabel('Threads')
    ax.set_ylabel('Number of Ops/sec')
    ax.plot(allThreads, allOps)
    ax.autoscale_view()
    
    # plot threads vs latency
    ax = fig.add_subplot(312)
    ax.set_title('Threads vs. Latency')
    ax.set_xlabel('Threads')
    ax.set_ylabel('Latency (microseconds)')
    ax.plot(allThreads, allLatency)
    ax.autoscale_view()

    # plot operations vs latency
    ax = fig.add_subplot(313)
    ax.set_title('Ops/sec vs. Latency')
    ax.set_ylabel('Latency(micros)')
    ax.set_xlabel('Ops/sec')
    ax.scatter(allOps, allLatency)
    ax.plot(allOps, bestfit)
    ax.autoscale_view()
    
    plt.show()
    # End plotting code

if __name__ == '__main__':
    main()
